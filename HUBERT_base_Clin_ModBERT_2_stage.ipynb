{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNbCC85FepTVMUBTgRvPKq5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMcGDNyTRiTR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install & Import Libraries and Check GPU"
      ],
      "metadata": {
        "id": "Urqp8eckSBk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "\n",
        "!pip install transformers[torch] datasets evaluate accelerate -q\n",
        "!pip install pandas scikit-learn -q\n",
        "\n",
        "# The accelerate library is useful for optimizing training, especially on multiple GPUs or TPUs,\n",
        "# and is a dependency for the Trainer.\n",
        "# pandas is for data manipulation if needed, and scikit-learn for metrics.\n",
        "\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import evaluate # Hugging Face's library for evaluation metrics\n",
        "\n",
        "# Check if GPU is available and set the device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"PyTorch is using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"PyTorch is using CPU. Training may be very slow.\")\n",
        "\n",
        "# Define the model checkpoint for Clinical_ModernBERT\n",
        "MODEL_CHECKPOINT = \"Simonlee711/Clinical_ModernBERT\" # [3]"
      ],
      "metadata": {
        "id": "quFBBnKOSP03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1: General Language Sentiment Prediction Fine-Tuning"
      ],
      "metadata": {
        "id": "1Pj9xfalSWhC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Dataset Selection and Loading"
      ],
      "metadata": {
        "id": "b0bWYeKJTScb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the SST-2 dataset from the GLUE benchmark\n",
        "# SST-2 is a binary sentiment classification task (positive/negative) [16]\n",
        "raw_datasets_stage1 = load_dataset(\"glue\", \"sst2\")\n",
        "\n",
        "print(\"Stage 1 Dataset (SST-2):\")\n",
        "print(raw_datasets_stage1)\n",
        "\n",
        "# SST-2 has 'sentence', 'label', 'idx' columns.\n",
        "# 'label' is 0 for negative, 1 for positive.\n",
        "# We will use 'sentence' as text and 'label' as the sentiment.\n",
        "\n",
        "# For demonstration, let's take a smaller subset for faster training\n",
        "# In a real scenario, you would use the full dataset.\n",
        "# For SST-2, 'train' is large, 'validation' is small.\n",
        "# We'll use a fraction of train and all of validation.\n",
        "\n",
        "# To create a consistent train/test split for demonstration if not using the full GLUE validation set\n",
        "# For GLUE tasks, standard splits are usually preferred.\n",
        "# Here, raw_datasets_stage1['train'] is the training set\n",
        "# raw_datasets_stage1['validation'] is the development/validation set\n",
        "# raw_datasets_stage1['test'] is the test set (labels often unavailable publicly)\n",
        "\n",
        "# Let's prepare our dataset dictionary\n",
        "# We'll use the provided train and validation splits\n",
        "train_df_stage1 = raw_datasets_stage1['train'].to_pandas()\n",
        "val_df_stage1 = raw_datasets_stage1['validation'].to_pandas()\n",
        "\n",
        "# For demonstration, if you want to further split the training set:\n",
        "# train_df_stage1, test_df_stage1 = train_test_split(train_df_stage1, test_size=0.1, random_state=42, stratify=train_df_stage1['label'])\n",
        "# For this protocol, we will use the official validation set as our test/eval set for Stage 1.\n",
        "\n",
        "# Convert pandas DataFrames back to Hugging Face Datasets\n",
        "train_dataset_stage1 = Dataset.from_pandas(train_df_stage1)\n",
        "eval_dataset_stage1 = Dataset.from_pandas(val_df_stage1)\n",
        "\n",
        "# Combine into a DatasetDict\n",
        "processed_datasets_stage1 = DatasetDict({\n",
        "    'train': train_dataset_stage1,\n",
        "    'validation': eval_dataset_stage1\n",
        "})\n",
        "\n",
        "print(\"\\nProcessed Stage 1 Datasets:\")\n",
        "print(processed_datasets_stage1)\n",
        "print(\"\\nExample from Stage 1 training set:\")\n",
        "print(processed_datasets_stage1['train'])"
      ],
      "metadata": {
        "id": "t6Pc2337StPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Preprocessing and Tokenization"
      ],
      "metadata": {
        "id": "8iIpqBRxTkyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer for Clinical_ModernBERT\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "# Define the maximum sequence length for Stage 1.\n",
        "# SST-2 sentences are relatively short.\n",
        "MAX_LENGTH_STAGE1 = 128 # [19] suggests 128 for SST-2 with DistilBERT\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function_stage1(examples):\n",
        "    # For SST-2, the text is in the 'sentence' column\n",
        "    return tokenizer(examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=MAX_LENGTH_STAGE1)\n",
        "\n",
        "# Apply tokenization to the datasets\n",
        "tokenized_datasets_stage1 = processed_datasets_stage1.map(tokenize_function_stage1, batched=True)\n",
        "\n",
        "# Remove columns that are not needed by the model and rename 'label' to 'labels'\n",
        "# The model expects the label column to be named 'labels' [14, 20]\n",
        "tokenized_datasets_stage1 = tokenized_datasets_stage1.remove_columns([\"sentence\", \"idx\"]) # SST-2 specific columns\n",
        "tokenized_datasets_stage1 = tokenized_datasets_stage1.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets_stage1.set_format(\"torch\") # Ensure datasets return PyTorch tensors\n",
        "\n",
        "print(\"\\nTokenized Stage 1 Datasets (showing train features):\")\n",
        "print(tokenized_datasets_stage1['train'].features)\n",
        "print(\"\\nExample of tokenized input_ids from Stage 1 training set:\")\n",
        "print(tokenized_datasets_stage1['train']['input_ids'])\n",
        "\n",
        "# Data collator for dynamic padding\n",
        "# This will pad sequences to the maximum length within a batch, which can be more efficient\n",
        "# than padding all sequences to MAX_LENGTH_STAGE1 if many are shorter.\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "32VLDmBSTh49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Model Initialization"
      ],
      "metadata": {
        "id": "ShAXloMjTsF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the number of labels for Stage 1 (SST-2 is binary)\n",
        "NUM_LABELS_STAGE1 = 2 # Positive, Negative\n",
        "\n",
        "# Load Clinical_ModernBERT with a sequence classification head\n",
        "model_stage1 = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_CHECKPOINT,\n",
        "    num_labels=NUM_LABELS_STAGE1,\n",
        "    # trust_remote_code=True # May be needed if the model has custom code, though often not for standard architectures\n",
        "    # torch_dtype=\"auto\" # To load in optimal memory data type [20]\n",
        ")\n",
        "\n",
        "# Move model to the configured device (GPU or CPU)\n",
        "model_stage1.to(device)\n",
        "\n",
        "print(f\"\\nStage 1 Model ({MODEL_CHECKPOINT}) loaded with a sequence classification head for {NUM_LABELS_STAGE1} labels.\")"
      ],
      "metadata": {
        "id": "ow8mjIMyTt0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4. Stage-1 General Training Protocol"
      ],
      "metadata": {
        "id": "UEcY6FIpTx7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define TrainingArguments for Stage 1\n",
        "training_args_stage1 = TrainingArguments(\n",
        "    output_dir=\"./results_stage1\",\n",
        "    learning_rate=2e-5,  # [15, 19]\n",
        "    per_device_train_batch_size=16, # Adjust based on GPU memory\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3, # [19]\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\", # Evaluate every epoch\n",
        "    save_strategy=\"epoch\",       # Save checkpoint every epoch\n",
        "    load_best_model_at_end=True, # Load the best model based on metric_for_best_model\n",
        "    metric_for_best_model=\"accuracy\", # For SST-2, accuracy is a common metric [16]\n",
        "    logging_dir='./logs_stage1',\n",
        "    logging_steps=100,\n",
        "    fp16=torch.cuda.is_available(), # Use mixed precision if GPU is available\n",
        "    # report_to=\"tensorboard\" # Optional: if you want to use tensorboard\n",
        ")\n",
        "\n",
        "# Define a function to compute metrics for evaluation\n",
        "def compute_metrics_stage1(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Using Hugging Face's evaluate library for standard metrics\n",
        "    accuracy_metric = evaluate.load(\"accuracy\")\n",
        "    f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "    acc = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"binary\") # For binary classification\n",
        "\n",
        "    # For multi-class, average might be \"macro\" or \"weighted\"\n",
        "    # For SST-2, it's binary.\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc[\"accuracy\"],\n",
        "        \"f1\": f1[\"f1\"],\n",
        "    }\n",
        "\n",
        "# Initialize Trainer for Stage 1\n",
        "trainer_stage1 = Trainer(\n",
        "    model=model_stage1,\n",
        "    args=training_args_stage1,\n",
        "    train_dataset=tokenized_datasets_stage1[\"train\"],\n",
        "    eval_dataset=tokenized_datasets_stage1[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics_stage1,\n",
        ")\n",
        "\n",
        "# Start Stage 1 training\n",
        "print(\"\\nStarting Stage 1 training...\")\n",
        "trainer_stage1.train()\n",
        "print(\"Stage 1 training finished.\")"
      ],
      "metadata": {
        "id": "OQ6KJAsrT1Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5. Evaluation and Model Saving"
      ],
      "metadata": {
        "id": "qdrMNEyEUJis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the fine-tuned Stage 1 model on its validation set\n",
        "print(\"\\nEvaluating Stage 1 model...\")\n",
        "eval_results_stage1 = trainer_stage1.evaluate()\n",
        "print(\"\\nStage 1 Evaluation Results:\")\n",
        "print(eval_results_stage1)\n",
        "\n",
        "# Save the fine-tuned Stage 1 model and tokenizer\n",
        "STAGE1_MODEL_PATH = \"./fine_tuned_clinical_modernbert_stage1\"\n",
        "trainer_stage1.save_model(STAGE1_MODEL_PATH)\n",
        "tokenizer.save_pretrained(STAGE1_MODEL_PATH) # Save tokenizer with the model\n",
        "\n",
        "print(f\"\\nStage 1 model and tokenizer saved to {STAGE1_MODEL_PATH}\")"
      ],
      "metadata": {
        "id": "2G02yajmULIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2: Healthcare-Domain Sentiment Prediction Fine-Tuning"
      ],
      "metadata": {
        "id": "rN9RoGVKUQrc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Load Stage-2 Healthcare Dataset"
      ],
      "metadata": {
        "id": "yjNIUXfwUSOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- STAGE 2: HEALTHCARE-DOMAIN SENTIMENT PREDICTION ---\n",
        "\n",
        "# IMPORTANT: Replace 'path/to/your/stage2_data.csv' with the actual path to your dataset.\n",
        "# The dataset should have 'text' and 'label' columns.\n",
        "# 'label' should be numerical (e.g., 0 for negative, 1 for neutral, 2 for positive).\n",
        "STAGE2_DATA_PATH = 'stage2_data.csv' # Placeholder\n",
        "\n",
        "# Example: Creating a dummy CSV file for demonstration purposes.\n",
        "# In a real scenario, you would upload or point to your actual data file.\n",
        "import pandas as pd\n",
        "dummy_stage2_data = {\n",
        "    'text':,\n",
        "    # Assuming 3 labels: 0=Negative, 1=Neutral, 2=Positive\n",
        "    'label':\n",
        "}\n",
        "dummy_stage2_df = pd.DataFrame(dummy_stage2_data)\n",
        "dummy_stage2_df.to_csv(STAGE2_DATA_PATH, index=False)\n",
        "print(f\"Dummy Stage 2 data created at {STAGE2_DATA_PATH}\")\n",
        "\n",
        "\n",
        "try:\n",
        "    # Load the custom dataset\n",
        "    # Assuming a CSV file with 'text' and 'label' columns\n",
        "    df_stage2 = pd.read_csv(STAGE2_DATA_PATH)\n",
        "    print(f\"\\nSuccessfully loaded Stage 2 data from {STAGE2_DATA_PATH}\")\n",
        "    print(\"Stage 2 DataFrame head:\")\n",
        "    print(df_stage2.head())\n",
        "\n",
        "    # Ensure 'text' and 'label' columns exist\n",
        "    if 'text' not in df_stage2.columns or 'label' not in df_stage2.columns:\n",
        "        raise ValueError(\"Stage 2 data must contain 'text' and 'label' columns.\")\n",
        "\n",
        "    # Determine the number of unique labels for Stage 2\n",
        "    NUM_LABELS_STAGE2 = df_stage2['label'].nunique()\n",
        "    print(f\"Number of unique labels in Stage 2 data: {NUM_LABELS_STAGE2}\")\n",
        "    if NUM_LABELS_STAGE2 <= 1:\n",
        "        raise ValueError(\"Stage 2 data must have at least two unique labels for classification.\")\n",
        "\n",
        "\n",
        "    # Split data into training and validation sets\n",
        "    train_df_stage2, val_df_stage2 = train_test_split(\n",
        "        df_stage2,\n",
        "        test_size=0.2, # 20% for validation\n",
        "        random_state=42,\n",
        "        stratify=df_stage2['label'] if NUM_LABELS_STAGE2 > 1 else None # Stratify if more than one label\n",
        "    )\n",
        "\n",
        "    # Convert pandas DataFrames to Hugging Face Datasets\n",
        "    train_dataset_stage2 = Dataset.from_pandas(train_df_stage2)\n",
        "    eval_dataset_stage2 = Dataset.from_pandas(val_df_stage2)\n",
        "\n",
        "    # Combine into a DatasetDict\n",
        "    raw_datasets_stage2 = DatasetDict({\n",
        "        'train': train_dataset_stage2,\n",
        "        'validation': eval_dataset_stage2\n",
        "    })\n",
        "\n",
        "    print(\"\\nRaw Stage 2 Datasets:\")\n",
        "    print(raw_datasets_stage2)\n",
        "    print(\"\\nExample from Stage 2 training set:\")\n",
        "    print(raw_datasets_stage2['train'])\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: Stage 2 data file not found at {STAGE2_DATA_PATH}. Please upload your data.\")\n",
        "except ValueError as e:\n",
        "    print(f\"ERROR: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred while loading Stage 2 data: {e}\")"
      ],
      "metadata": {
        "id": "baV9r-76UjLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Model Initialization from Stage-1"
      ],
      "metadata": {
        "id": "Y9tsVbscUpJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path where Stage 1 model was saved\n",
        "# STAGE1_MODEL_PATH = \"./fine_tuned_clinical_modernbert_stage1\" # Defined in Stage 1\n",
        "\n",
        "if 'NUM_LABELS_STAGE2' in locals() and NUM_LABELS_STAGE2 > 1:\n",
        "    # Load the fine-tuned Stage 1 model\n",
        "    # Ensure the number of labels matches the Stage 2 dataset\n",
        "    model_stage2 = AutoModelForSequenceClassification.from_pretrained(\n",
        "        STAGE1_MODEL_PATH,\n",
        "        num_labels=NUM_LABELS_STAGE2,\n",
        "        # trust_remote_code=True # If applicable\n",
        "    )\n",
        "\n",
        "    # The tokenizer is the same as Stage 1, already loaded.\n",
        "    # If not, load it: tokenizer = AutoTokenizer.from_pretrained(STAGE1_MODEL_PATH)\n",
        "\n",
        "    model_stage2.to(device)\n",
        "    print(f\"\\nStage 2 Model loaded from {STAGE1_MODEL_PATH} with a new classification head for {NUM_LABELS_STAGE2} labels.\")\n",
        "else:\n",
        "    print(\"Skipping Stage 2 model initialization as NUM_LABELS_STAGE2 is not properly defined.\")"
      ],
      "metadata": {
        "id": "4hvi1ZoIVZ8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3. Stage-2 Healthcare-Domain Training Protocol"
      ],
      "metadata": {
        "id": "PTuijtYOVdXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'model_stage2' in locals() and model_stage2 is not None and \\\n",
        "   'tokenized_datasets_stage2' in locals() and tokenized_datasets_stage2 is not None:\n",
        "\n",
        "    training_args_stage2 = TrainingArguments(\n",
        "        output_dir=\"./results_stage2\",\n",
        "        learning_rate=1e-5,  # Lower learning rate for second stage fine-tuning\n",
        "        per_device_train_batch_size=8, # Potentially smaller due to longer MAX_LENGTH_STAGE2\n",
        "        per_device_eval_batch_size=8,\n",
        "        num_train_epochs=3, # Adjust as needed\n",
        "        weight_decay=0.01,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1_macro\" if NUM_LABELS_STAGE2 > 2 else \"f1\", # Use f1_macro for multi-class\n",
        "        logging_dir='./logs_stage2',\n",
        "        logging_steps=50,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        # report_to=\"tensorboard\"\n",
        "    )\n",
        "\n",
        "    def compute_metrics_stage2(eval_pred):\n",
        "        logits, labels = eval_pred\n",
        "        predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "        accuracy_metric = evaluate.load(\"accuracy\")\n",
        "        precision_metric = evaluate.load(\"precision\")\n",
        "        recall_metric = evaluate.load(\"recall\")\n",
        "        f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "        acc = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "        # Adjust averaging for multi-class if NUM_LABELS_STAGE2 > 2\n",
        "        avg_method = \"macro\" if NUM_LABELS_STAGE2 > 2 else \"binary\"\n",
        "\n",
        "        precision = precision_metric.compute(predictions=predictions, references=labels, average=avg_method, zero_division=0)\n",
        "        recall = recall_metric.compute(predictions=predictions, references=labels, average=avg_method, zero_division=0)\n",
        "        f1 = f1_metric.compute(predictions=predictions, references=labels, average=avg_method, zero_division=0)\n",
        "\n",
        "        return {\n",
        "            \"accuracy\": acc[\"accuracy\"],\n",
        "            \"precision_macro\" if avg_method == \"macro\" else \"precision\": precision[\"precision\"],\n",
        "            \"recall_macro\" if avg_method == \"macro\" else \"recall\": recall[\"recall\"],\n",
        "            \"f1_macro\" if avg_method == \"macro\" else \"f1\": f1[\"f1\"],\n",
        "        }\n",
        "\n",
        "    trainer_stage2 = Trainer(\n",
        "        model=model_stage2,\n",
        "        args=training_args_stage2,\n",
        "        train_dataset=tokenized_datasets_stage2[\"train\"],\n",
        "        eval_dataset=tokenized_datasets_stage2[\"validation\"],\n",
        "        tokenizer=tokenizer, # Same tokenizer\n",
        "        data_collator=data_collator, # Same data collator\n",
        "        compute_metrics=compute_metrics_stage2,\n",
        "    )\n",
        "\n",
        "    print(\"\\nStarting Stage 2 training...\")\n",
        "    trainer_stage2.train()\n",
        "    print(\"Stage 2 training finished.\")\n",
        "else:\n",
        "    print(\"Skipping Stage 2 training as prerequisite variables are not available.\")"
      ],
      "metadata": {
        "id": "IRU-8uCKVnmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4. Evaluation and Final Model Saving"
      ],
      "metadata": {
        "id": "d5WMNfhIVq5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'trainer_stage2' in locals() and trainer_stage2 is not None:\n",
        "    print(\"\\nEvaluating final Stage 2 model...\")\n",
        "    eval_results_stage2 = trainer_stage2.evaluate()\n",
        "    print(\"\\nStage 2 Evaluation Results (Final Model):\")\n",
        "    print(eval_results_stage2)\n",
        "\n",
        "    # Save the final fine-tuned model and tokenizer\n",
        "    FINAL_MODEL_PATH = \"./final_sentiment_model_clinical_modernbert_sdn\"\n",
        "    trainer_stage2.save_model(FINAL_MODEL_PATH)\n",
        "    tokenizer.save_pretrained(FINAL_MODEL_PATH) # Save the tokenizer with the final model\n",
        "\n",
        "    print(f\"\\nFinal domain-adapted model and tokenizer saved to {FINAL_MODEL_PATH}\")\n",
        "else:\n",
        "    print(\"Skipping Stage 2 evaluation and saving as trainer_stage2 is not available.\")"
      ],
      "metadata": {
        "id": "TGb4JZ_cVt_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilizing HUBERT for Sentiment Analysis"
      ],
      "metadata": {
        "id": "ORzkbqWWVxGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 1.1. Loading Model for Inference"
      ],
      "metadata": {
        "id": "KC4Vm1xDV588"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- INFERENCE WITH THE FINAL MODEL ---\n",
        "# FINAL_MODEL_PATH = \"./final_sentiment_model_clinical_modernbert_sdn\" # Defined in Stage 2\n",
        "\n",
        "# Load the final fine-tuned model and tokenizer\n",
        "try:\n",
        "    final_model = AutoModelForSequenceClassification.from_pretrained(FINAL_MODEL_PATH)\n",
        "    # The tokenizer should also be loaded from the final model path to ensure consistency\n",
        "    final_tokenizer = AutoTokenizer.from_pretrained(FINAL_MODEL_PATH)\n",
        "\n",
        "    final_model.to(device) # Move model to GPU if available\n",
        "    final_model.eval()     # Set model to evaluation mode\n",
        "\n",
        "    print(f\"\\nFinal model and tokenizer loaded from {FINAL_MODEL_PATH} for inference.\")\n",
        "\n",
        "    # Define human-readable labels if NUM_LABELS_STAGE2 was, for example, 3\n",
        "    # This depends on how labels were encoded (0, 1, 2) during Stage 2 data prep.\n",
        "    # Example:\n",
        "    if 'NUM_LABELS_STAGE2' in locals() and NUM_LABELS_STAGE2 == 3:\n",
        "        sentiment_labels_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
        "        # If your labels are different (e.g., -1, 0, 1 or 1, 2, 3), adjust this map.\n",
        "        # Ensure this map aligns with the numeric labels used in your stage2_data.csv\n",
        "    elif 'NUM_LABELS_STAGE2' in locals() and NUM_LABELS_STAGE2 == 2: # For binary like SST-2\n",
        "        sentiment_labels_map = {0: \"Negative\", 1: \"Positive\"}\n",
        "    else:\n",
        "        sentiment_labels_map = None\n",
        "        print(\"Warning: NUM_LABELS_STAGE2 not clearly defined for sentiment_labels_map. Predictions will be numeric.\")\n",
        "\n",
        "\n",
        "    # Prediction function\n",
        "    def predict_sentiment(text, model, tokenizer, max_length=MAX_LENGTH_STAGE2): # Use MAX_LENGTH_STAGE2\n",
        "        # Preprocess the input text (apply the same cleaning as in Stage 2)\n",
        "        cleaned_text = preprocess_forum_text(text) # Ensure this function is defined and accessible\n",
        "\n",
        "        inputs = tokenizer(\n",
        "            cleaned_text,\n",
        "            padding=\"max_length\", # Or True, if using data_collator logic implicitly\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors=\"pt\" # Return PyTorch tensors\n",
        "        )\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()} # Move inputs to the same device as the model\n",
        "\n",
        "        with torch.no_grad(): # Disable gradient calculations for inference\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            probabilities = torch.softmax(logits, dim=-1)\n",
        "            predicted_class_id = torch.argmax(probabilities, dim=-1).item()\n",
        "\n",
        "        if sentiment_labels_map:\n",
        "            predicted_label = sentiment_labels_map.get(predicted_class_id, \"Unknown\")\n",
        "        else:\n",
        "            predicted_label = predicted_class_id\n",
        "\n",
        "        return {\n",
        "            \"predicted_label\": predicted_label,\n",
        "            \"predicted_class_id\": predicted_class_id,\n",
        "            \"probabilities\": probabilities.cpu().numpy().tolist() # Convert to list for easier handling\n",
        "        }\n",
        "\n",
        "    # Example forum post snippets for prediction\n",
        "    sample_posts =\n",
        "\n",
        "    print(\"\\n--- Example Predictions ---\")\n",
        "    for i, post_text in enumerate(sample_posts):\n",
        "        if final_model and final_tokenizer:\n",
        "            prediction_result = predict_sentiment(post_text, final_model, final_tokenizer)\n",
        "            print(f\"\\nPost {i+1}: \\\"{post_text}\\\"\")\n",
        "            print(f\"  Predicted Sentiment: {prediction_result['predicted_label']} (ID: {prediction_result['predicted_class_id']})\")\n",
        "            if sentiment_labels_map and prediction_result['probabilities']:\n",
        "                 # Print probabilities per label\n",
        "                prob_strings = [f\"{sentiment_labels_map.get(j, str(j))}: {prob:.4f}\" for j, prob in enumerate(prediction_result['probabilities'])]\n",
        "                print(f\"  Probabilities: [{', '.join(prob_strings)}]\")\n",
        "            else:\n",
        "                print(f\"  Probabilities: {prediction_result['probabilities']}\")\n",
        "        else:\n",
        "            print(\"Final model or tokenizer not available for prediction.\")\n",
        "\n",
        "except NameError as e:\n",
        "    print(f\"Error during inference setup (likely a variable like FINAL_MODEL_PATH was not defined due to earlier skips): {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred during inference: {e}\")"
      ],
      "metadata": {
        "id": "fExkjjM8V_B8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}